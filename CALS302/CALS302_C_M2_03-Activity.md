# Activity: Synthesizing the Impact of Different Corrective Techniques on Predictive Uncertainties

Every time we take a step toward clarity in climate science, we seem to kick up a little more dust. We sharpen the resolution of our models, build better corrections, fill in the blanks with physics‚Äîbut uncertainty, like the wind, keeps changing direction. And so we learn to live with it, not by ignoring it, but by listening to what it tells us. Applying advanced modeling techniques such as downscaling or bias correction introduces uncertainty of their own (Wootten et al., 2017; Lafferty & Sriver, 2023).

This exercise invites you to do just that. The Colorado River, winding its way through the arid heart of the West, is more than just a water source. It is a bellwether‚Äîa place where science, policy, and public need collide. Predicting its flow is a bit like guessing the mood of a mountain range. Yet, with careful observation, we can begin to understand not just the guesses, but the shape of our not knowing. The basin is the primary water source for over 30 million people and underpins critical ecosystems and economies (Lettenmaier et al., 2014).

---

## üìä Part 1: Interpreting the Data

Below is a simple table. It speaks in numbers, but the questions behind them are deeply human: How much water will there be? Can we count on it? And what might throw our predictions off course?

| Climate Projection Case | Downscaling Uncertainty (cfs) | Natural Variability (cfs) | Multi-Model Spread (cfs) | Total Uncertainty (cfs) |
|-------------------------|-------------------------------|---------------------------|---------------------------|--------------------------|
| A                       | 250                           | 400                       | 350                       | ?                        |
| B                       | 300                           | 300                       | 500                       | ?                        |
| C                       | 200                           | 500                       | 300                       | ?                        |

**Q1:** Add up the uncertainty contributions for each case.

**Answer Feedback:**

- Total = Downscaling + Natural Variability + Multi-Model Spread  
- A = 1000 cfs, B = 1100 cfs, C = 1000 cfs  
- *Why it matters:* These sums don‚Äôt predict the future, but they frame its uncertainty‚Äîlike measuring the width of a fog bank before driving through (IPCC, 2021a).

---

## üìà Part 2: Visualizing Proportional Contributions

Now let‚Äôs give the numbers some shape. Create a pie chart for Case B. Watch how the parts of uncertainty divvy up the circle.

**Q2:** Which piece is largest, and what does that tell us?

**Answer Feedback:**

- Multi-model spread is the lion‚Äôs share‚Äînearly half.  
- *Interpretation:* When even the models disagree, it‚Äôs not enough to seek sharper tools; we need steadier hands and broader plans. We aren‚Äôt chasing precision here‚Äîwe‚Äôre learning how to hold ambiguity without letting it paralyze us (IPCC, 2021b; Hawkins & Sutton, 2009).

---

## üß† Part 3: Reflecting on Implications

Behind every chart is a choice, and behind every choice is a person trying to do the right thing with incomplete information.

Match the types of uncertainty with the real-world dilemmas they‚Äôre most likely to complicate.

| Stakeholder Challenge | Match the Uncertainty Source |
|-----------------------|-------------------------------|
| ‚ÄúWe know a drought might happen, but not when.‚Äù | ? |
| ‚ÄúGlobal models don‚Äôt zoom in well enough on my basin.‚Äù | ? |
| ‚ÄúWe‚Äôve run 20 models and none agree.‚Äù | ? |

**Answer Feedback:**

- Natural Variability ‚Üí drought timing  
- Downscaling ‚Üí poor local detail  
- Multi-Model Spread ‚Üí divergent visions  
- *Why it matters:* Each kind of uncertainty lives on a different timescale, demands a different kind of patience. Knowing which is which gives us more than answers‚Äîit gives us perspective (NAS, 2016; JBA Risk, 2023).

---

## üîö Conclusion

Uncertainty is not a crack in the glass‚Äîit‚Äôs the glass itself. We don‚Äôt peer through it to see something perfect; we peer through it to see something meaningful. In understanding what makes our predictions shaky, we begin to see what holds them together. And sometimes, that's all we need to start making good decisions, even when the sky is unclear.

---

## üìñ References (APA 7)

- Hawkins, E., & Sutton, R. (2009). The potential to narrow uncertainty in regional climate predictions. *Bulletin of the American Meteorological Society*, 90(8), 1095‚Äì1107.

- Intergovernmental Panel on Climate Change. (2021a). *Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report* (Section 4). Cambridge University Press.

- Intergovernmental Panel on Climate Change. (2021b). *Climate Change 2021: The Physical Science Basis. Contribution of Working Group I to the Sixth Assessment Report* (Section 10). Cambridge University Press.

- JBA Risk Management. (2023). *Modelling and Uncertainty: The Extra Dimension*. https://www.jbarisk.com/knowledge-hub/insights/modelling-and-uncertainty-the-extra-dimension/

- Lafferty, A. M., & Sriver, R. L. (2023). Downscaling and bias correction uncertainty in CMIP6 climate projections. *npj Climate and Atmospheric Science*, 6(1). https://doi.org/10.1038/s41612-023-00486-0

- Lettenmaier, D. P., et al. (2014). Climate change and the hydrology of the Colorado River Basin. *Bulletin of the American Meteorological Society*, 95(1), 146-149.

- National Academies of Sciences, Engineering, and Medicine. (2016). *Attribution of extreme weather events in the context of climate change*. The National Academies Press.

- U.S. Global Change Research Program. (2017). *Climate Science Special Report: Fourth National Climate Assessment, Volume I*. https://science2017.globalchange.gov/

- Wootten, A., et al. (2017). Characterizing sources of uncertainty in climate models and downscaling techniques. *Journal of Applied Meteorology and Climatology*, 56(7), 1931‚Äì1946.

